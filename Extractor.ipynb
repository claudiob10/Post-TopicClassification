{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extractor MongoDB a .JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sshtunnel import SSHTunnelForwarder\n",
    "import pymongo\n",
    "import pprint\n",
    "import json\n",
    "from bson import json_util\n",
    "import time\n",
    "import threading\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extractor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print time before before extract data\n",
    "time1 = time.asctime()\n",
    "print(time1)\n",
    "\n",
    "# Credentials of MongoDB Prod\n",
    "MONGO_HOST = \"IP\"\n",
    "MONGO_USER = \"USER\"\n",
    "MONGO_PASS = \"PASSWORD\"\n",
    "PEM = \"D:/Topic Flower/db\"\n",
    "MONGO_DB = \"topicflower_prod\"\n",
    "MONGO_COLLECTION = \"COLLECTION\"\n",
    "\n",
    "# Define local path\n",
    "path = r'C:\\Users\\Darwoft\\PostClassification\\PostClasification\\topics\\\\'\n",
    "\n",
    "\n",
    "def extraer_coleccion(cole):\n",
    "    collection = db[cole]\n",
    "\n",
    "    # NoSql query to MongoDB to extract the first 100.000 post\n",
    "    cursor = collection.find({\"$and\": [{'topic': {\"$ne\": None}}, {\"$or\": [{'twitter': {\"$ne\": None}}, {'data_facebook': {\"$ne\": None}}]}]}, {\n",
    "                             \"brandname\": 1, \"topic\": 1, \"topicname\": 1, \"twitter.posttext\": 1, \"data_facebook.message\": 1}).limit(100000)\n",
    "    texto = '['\n",
    "    for fut in cursor:\n",
    "        texto = texto + json.dumps(fut,  default=json_util.default) + ','\n",
    "    texto = texto[:-1]\n",
    "    texto = texto + ']'\n",
    "    archivo_post = path + str(cole)+'.json'\n",
    "\n",
    "    # Save the query data into a .json file\n",
    "    with open(archivo_post, 'w', encoding='UTF-8') as file:\n",
    "        file.write(texto)\n",
    "    return None\n",
    "\n",
    "\n",
    "# Define SSH Tunnel\n",
    "server = SSHTunnelForwarder(\n",
    "    MONGO_HOST,\n",
    "    ssh_username=MONGO_USER,\n",
    "    ssh_pkey=PEM,\n",
    "    remote_bind_address=('127.0.0.1', 27017)\n",
    ")\n",
    "\n",
    "# Start SSH tunnel\n",
    "server.start()\n",
    "\n",
    "# Server.local_bind_port is assigned local port\n",
    "client = pymongo.MongoClient(\n",
    "    '127.0.0.1', server.local_bind_port, maxPoolSize=50, waitQueueMultiple=10)\n",
    "db = client[MONGO_DB]\n",
    "\n",
    "# call Function to extract Post collection data\n",
    "extraer_coleccion('post')\n",
    "\n",
    "# Close connection\n",
    "client.close()\n",
    "server.stop()\n",
    "time2 = time.asctime()\n",
    "\n",
    "# Print time for the whole process\n",
    "print(time2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert .Json to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Before convert the .json to CSV file we need to find and replace the \"data_facebook\":Â¨{}\n",
    "because to make it work we need to replace it for \"data_facebook\": {\"message\": \"\"}\n",
    "If not we will have a error before convert to CSV file\n",
    "This will be update in the future \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convertor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Json and CSV files\n",
    "archivo_post = r'C:\\Users\\Darwoft\\PostClassification\\PostClasification\\topics\\post.json'\n",
    "archivo_sent = r'C:\\Users\\Darwoft\\PostClassification\\PostClasification\\topics\\Topics-text.csv'\n",
    "\n",
    "# Open Json file\n",
    "with open(archivo_post, 'r', encoding='UTF-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "\n",
    "facebooktext = ''\n",
    "twittertext = ''\n",
    "\n",
    "# Define CSV columns\n",
    "texto = \"id,brandname,topic,topicname,twittertext,facebooktext\" + '\\n'\n",
    "\n",
    "for f in data:\n",
    "    try:\n",
    "        ID = f.get('_id').get('$oid')\n",
    "        brandname = f.get('brandname')\n",
    "        topic = f.get('topic')\n",
    "        topic = topic.lower()\n",
    "        topicname = f.get('topicname')\n",
    "        twittertext = f.get('twitter').get('posttext')\n",
    "\n",
    "        # Delete special characters, URL and Tags from the post\n",
    "        twittertext = twittertext.replace(',', '')\n",
    "        twittertext = twittertext.replace('\\n', '')\n",
    "        twittertext = twittertext.replace('\\\"', '')\n",
    "        twittertext = twittertext.replace('\"', '')\n",
    "        twittertext = re.sub(r\"http\\S+\", '', twittertext)\n",
    "        twittertext = re.sub(r\"@\\S+\", '', twittertext)\n",
    "    except:\n",
    "        facebooktext = f.get('data_facebook').get('message')\n",
    "\n",
    "        # Delete special characters, URL and Tags from the post\n",
    "        facebooktext = facebooktext.replace(',', '')\n",
    "        facebooktext = facebooktext.replace('\\n', '')\n",
    "        facebooktext = facebooktext.replace('\\\"', '')\n",
    "        facebooktext = facebooktext.replace('\"', '')\n",
    "        facebooktext = re.sub(r\"http\\S+\", '', facebooktext)\n",
    "        facebooktext = re.sub(r\"@\\S+\", '', facebooktext)\n",
    "\n",
    "    # Create CSV estruture separate by \",\"\n",
    "    texto = texto + str(ID) + \",\" + str(brandname) + \",\" + str(topic) + \",\" + \\\n",
    "        str(topicname) + \",\" + str(twittertext) + \",\" + str(facebooktext)+'\\n'\n",
    "    facebooktext = ''\n",
    "    twittertext = ''\n",
    "\n",
    "# Open and write in the CSV File\n",
    "with open(archivo_sent, 'w', encoding='UTF-8') as file:\n",
    "    file.write(texto)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
